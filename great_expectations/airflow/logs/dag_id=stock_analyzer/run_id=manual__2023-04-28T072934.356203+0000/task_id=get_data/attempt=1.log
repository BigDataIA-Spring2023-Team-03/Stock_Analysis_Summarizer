[2023-04-28T07:29:59.622+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: stock_analyzer.get_data manual__2023-04-28T07:29:34.356203+00:00 [queued]>
[2023-04-28T07:29:59.675+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: stock_analyzer.get_data manual__2023-04-28T07:29:34.356203+00:00 [queued]>
[2023-04-28T07:29:59.676+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2023-04-28T07:29:59.676+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 1
[2023-04-28T07:29:59.677+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2023-04-28T07:29:59.770+0000] {taskinstance.py:1300} INFO - Executing <Task(PythonOperator): get_data> on 2023-04-28 07:29:34.356203+00:00
[2023-04-28T07:29:59.785+0000] {standard_task_runner.py:55} INFO - Started process 530 to run task
[2023-04-28T07:29:59.793+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'stock_analyzer', 'get_data', 'manual__2023-04-28T07:29:34.356203+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/main.py', '--cfg-path', '/tmp/tmpctrtvt89']
[2023-04-28T07:29:59.793+0000] {standard_task_runner.py:83} INFO - Job 4: Subtask get_data
[2023-04-28T07:30:00.020+0000] {task_command.py:388} INFO - Running <TaskInstance: stock_analyzer.get_data manual__2023-04-28T07:29:34.356203+00:00 [running]> on host e48c557aa0b5
[2023-04-28T07:30:00.281+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=stock_analyzer
AIRFLOW_CTX_TASK_ID=get_data
AIRFLOW_CTX_EXECUTION_DATE=2023-04-28T07:29:34.356203+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-04-28T07:29:34.356203+00:00
[2023-04-28T07:30:00.286+0000] {connection.py:287} INFO - Snowflake Connector for Python Version: 3.0.3, Python Version: 3.7.16, Platform: Linux-5.15.90.1-microsoft-standard-WSL2-x86_64-with-debian-11.6
[2023-04-28T07:30:00.287+0000] {connection.py:990} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-04-28T07:30:00.288+0000] {connection.py:1007} INFO - Setting use_openssl_only mode to False
[2023-04-28T07:30:03.332+0000] {cursor.py:800} INFO - query: [SELECT * FROM users]
[2023-04-28T07:30:04.352+0000] {cursor.py:813} INFO - query execution done
[2023-04-28T07:30:04.353+0000] {cursor.py:956} INFO - Number of results in first chunk: 5
[2023-04-28T07:30:04.430+0000] {taskinstance.py:1768} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/main.py", line 50, in get_data
    df.to_csv(file_path, index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 3482, in to_csv
    storage_options=storage_options,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/formats/format.py", line 1105, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/formats/csvs.py", line 243, in save
    storage_options=self.storage_options,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '../working_dir/data/user.csv'
[2023-04-28T07:30:04.451+0000] {taskinstance.py:1323} INFO - Marking task as FAILED. dag_id=stock_analyzer, task_id=get_data, execution_date=20230428T072934, start_date=20230428T072959, end_date=20230428T073004
[2023-04-28T07:30:04.476+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 4 for task get_data ([Errno 2] No such file or directory: '../working_dir/data/user.csv'; 530)
[2023-04-28T07:30:04.510+0000] {local_task_job.py:208} INFO - Task exited with return code 1
